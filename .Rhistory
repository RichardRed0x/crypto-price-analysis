library(rjson)
comments.journal = rjson::fromJSON(file="https://raw.githubusercontent.com/decred-proposals/mainnet/master/c68bb790ba0843980bb9695de4628995e75e0d1f36c992951db49eca7b3b4bcd/2/plugins/decred/comments.journal")
comments.journal
comments.journal[1]
?fromJSON
URL = "https://raw.githubusercontent.com/decred-proposals/mainnet/master/c68bb790ba0843980bb9695de4628995e75e0d1f36c992951db49eca7b3b4bcd/2/plugins/decred/comments.journal"
filepath = paste(URL, sep="")
jsondata = file(filepath, "r")
json = readLines(jsondata)
close(jsondata)
JSONimport = fromJSON(json)
head(JSONimport)
View(JSONimport)
json
nrow(json)
typeof(json)
json[1]
json[2]
json[3]
json[1][2]
JSONimport = fromJSON(json[1])
JSONimport
js1 = lapply(readLines(jsondata), fromJSON, flatten = TRUE)
js1 = lapply(readLines(json), fromJSON, flatten = TRUE)
js1 = lapply(readLines(json), fromJSON, flatten = TRUE)
json
js1 = lapply(readLines(json), fromJSON, flatten = TRUE)
jsondata = file(filepath, "r")
js1 = lapply(readLines(json), fromJSON, flatten = TRUE)
close(jsondata)
filepath = paste(URL, sep="")
jsondata = file(filepath, "r")
js1 = lapply(readLines(json), fromJSON, flatten = TRUE)
close(jsondata)
library(jsonlite)
library(ggplot2)
library(reshape2)
library(jsonlite)
forks2016 = read.csv("dcrforks2016.csv", stringsAsFactors = FALSE)
forks2017 = read.csv("dcrforks2017.csv", stringsAsFactors = FALSE)
forks2018 = read.csv("dcrforks2018.csv", stringsAsFactors = FALSE)
forkevents = rbind(forks2016,forks2017, forks2018)
forkevents$shortname = sub(".*/", "", forkevents$repo_name)
d.forks = dcast(forkevents, repo_name ~ type)
d.forks$shortname =  sub(".*/", "", d.forks$repo_name)
d.forks.events = dcast(d.forks, shortname ~ .)
p.repo.forks = ggplot(d.forks.events[d.forks.events$. > 10,], aes(x = factor(shortname), y = .))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(x = "Repository - only showing those with > 10 forks", y = "Number of Forks", title = "Number of forks (with events) per repository")
library(ggplot2)
setwd("E:\\Dropbox\\rmills\\Wikirate\\quant features\\metric data to import\\uk gender pay gap\\working")
df1 = read.csv("UK Gender Pay Gap Data - 2017 to 2018.csv", stringsAsFactors = FALSE)
df2 = read.csv("UK Gender Pay Gap Data - 2018 to 2019.csv", stringsAsFactors = FALSE)
df1$year = 2018
df2$year = 2019
df = rbind(df1, df2)
df = df[df$DiffMeanHourlyPercent >= -100 & df$DiffMeanHourlyPercent <= 100,]
df = df[df$DiffMeanBonusPercent >= -100 & df$DiffMeanBonusPercent <= 100,]
df = df[!is.na(df$DiffMeanBonusPercent),]
#do some graphs by year to warm up
p.diff.hist = ggplot(df, aes(DiffMeanHourlyPercent))+
geom_histogram()+
facet_wrap(EmployerSize ~ year , ncol = 2, scales = "free_y")+
geom_vline(xintercept = 0)
p.diff.hist.bonus = ggplot(df, aes(DiffMeanBonusPercent))+
geom_histogram()+
facet_wrap(EmployerSize ~ year , ncol = 2, scales = "free_y")+
geom_vline(xintercept = 0)
superblocks.raw = getURL("https://api.dashintel.org/dash_budget_periods")
superblocks = fromJSON(superblocks.raw)
library(jsonlite)
head(dash_central_proposals)
dash_central_proposals.raw = getURL("https://api.dashintel.org/dash_central_proposals")
dash_central_proposals = fromJSON(dash_central_proposals.raw)
library(RCurl)
dash_central_proposals.raw = getURL("https://api.dashintel.org/dash_central_proposals")
dash_central_proposals = fromJSON(dash_central_proposals.raw)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
head(dash_central_proposals)
names(dash_central_proposals)
View(dash_central_proposals)
dash_central_proposals = dash_central_proposals[dash_central_proposals$startbudgetperiodtime <= Sys.time(),]
dash_central_proposals = dash_central_proposals[as.PosixCT(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dash_central_proposals = dash_central_proposals[as.POSIXct(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dash_central_proposals = dash_central_proposals[as.POSIXlt(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
as.POSIXlt(dash_central_proposals$startbudgetperiodtime[1])
as.POSIXct(dash_central_proposals$startbudgetperiodtime[1])
dash_central_proposals$startbudgetperiodtime[1]
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
nrow(dash_central_proposals)
dash_central_proposals = fromJSON(dash_central_proposals.raw)
nrow(dash_central_proposals)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dashprops = subset(dash_central_proposals, select = c("url", "title", "yes", "no", "abstain", "id", "date_added", "date_end", "budget_periods_timestamp", "startbudgetperiodtime"))
dashprops$eligible_voters = 0
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
dashprops$total_votes = dashprops$yes + dashprops$no + dashprops$abstain
dashprops$voter_participation = (dashprops$total_votes/dashprops$eligible_voters)*100
dashprops.finite = dashprops[is.finite(dashprops$voter_participation),]
dash = dashprops.finite
names(dash)[names(dash)=="yes"] <- "yes_votes"
names(dash)[names(dash)=="no"] <- "no_votes"
names(dash)[names(dash)=="date_added"] <- "voting_startdate"
names(dash)[names(dash)=="date_end"] <- "voting_enddate"
dash$project = "Dash"
dash = subset(dash, select = c("title","url","yes_votes","no_votes","total_votes","voter_participation","voting_startdate","voting_enddate","project","eligible_voters"))
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
dash_central_proposals.raw = getURL("https://api.dashintel.org/dash_central_proposals")
dash_central_proposals = fromJSON(dash_central_proposals.raw)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dashprops = subset(dash_central_proposals, select = c("url", "title", "yes", "no", "abstain", "id", "date_added", "date_end", "budget_periods_timestamp", "startbudgetperiodtime"))
dashprops$eligible_voters = 0
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
dashprops$total_votes = dashprops$yes + dashprops$no + dashprops$abstain
dashprops$voter_participation = (dashprops$total_votes/dashprops$eligible_voters)*100
dashprops.finite = dashprops[is.finite(dashprops$voter_participation),]
dash = dashprops.finite
names(dash)[names(dash)=="yes"] <- "yes_votes"
names(dash)[names(dash)=="no"] <- "no_votes"
names(dash)[names(dash)=="date_added"] <- "voting_startdate"
names(dash)[names(dash)=="date_end"] <- "voting_enddate"
dash$project = "Dash"
dash = subset(dash, select = c("title","url","yes_votes","no_votes","total_votes","voter_participation","voting_startdate","voting_enddate","project","eligible_voters"))
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
dash = read.csv("dash-proposals.csv", stringsAsFactors = FALSE)
decred.consensus = read.csv("decred-proposals-onchain.csv", stringsAsFactors = FALSE)
decred.consensus$total_votes = decred.consensus$yes_votes+decred.consensus$no_votes
decred.consensus$voter_participation = (decred.consensus$total_votes/decred.consensus$eligible_voters)*100
dash = read.csv("dash-proposals.csv", stringsAsFactors = FALSE)
nrow(dash)
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
head(dash)
dash_central_proposals = fromJSON(dash_central_proposals.raw)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dashprops = subset(dash_central_proposals, select = c("url", "title", "yes", "no", "abstain", "id", "date_added", "date_end", "budget_periods_timestamp", "startbudgetperiodtime"))
dashprops$eligible_voters = 0
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
mvdash_proposals_unified.raw = getURL("https://api.dashintel.org/mvdash_proposals_unified")
mvdash_proposals_unified = fromJSON(mvdash_proposals_unified.raw)
write.csv(mvdash_proposals_unified, file = "mvdash_proposals_unified.csv", row.names = FALSE)
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
dash_masternode_insights.raw = getURL("https://api.dashintel.org/dash_masternode_insights")
dash_masternode_insights = fromJSON(dash_masternode_insights.raw)
#write.csv(dash_masternode_insights, file = "dash_masternode_insights.csv", row.names = FALSE)
dash_mn_count.raw = getURL("https://api.dashintel.org/dash_mn_count")
dash_mn_count = fromJSON(dash_mn_count.raw)
#write.csv(dash_mn_count, file = "dash_mn_count.csv", row.names = FALSE)
dash_proposal_tags.raw = getURL("https://api.dashintel.org/dash_proposal_tags")
dash_proposal_tags = fromJSON(dash_proposal_tags.raw)
#write.csv(dash_proposal_tags, file = "dash_proposal_tags.csv", row.names = FALSE)
dash_price_history.raw = getURL("https://api.dashintel.org/dash_price_history")
dash_price_history = fromJSON(dash_price_history.raw)
#write.csv(dash_price_history, file = "dash_price_history.csv", row.names = FALSE)
mvdash_proposals_unified.raw = getURL("https://api.dashintel.org/mvdash_proposals_unified")
mvdash_proposals_unified = fromJSON(mvdash_proposals_unified.raw)
#write.csv(mvdash_proposals_unified, file = "mvdash_proposals_unified.csv", row.names = FALSE)
mvdash_total_and_available_masternodes.raw = getURL("https://api.dashintel.org/mvdash_total_and_available_masternodes ")
mvdash_total_and_available_masternodes  = fromJSON(mvdash_total_and_available_masternodes.raw)
#write.csv(mvdash_total_and_available_masternodes , file = "mvdash_total_and_available_masternodes.csv", row.names = FALSE)
mvdash_vote_type_count_by_period.raw = getURL("https://api.dashintel.org/mvdash_vote_type_count_by_period ")
mvdash_vote_type_count_by_period  = fromJSON(mvdash_vote_type_count_by_period.raw)
#write.csv(mvdash_vote_type_count_by_period , file = "mvdash_vote_type_count_by_period.csv", row.names = FALSE)
mvdash_votes_by_week_and_hour.raw = getURL("https://api.dashintel.org/mvdash_votes_by_week_and_hour ")
mvdash_votes_by_week_and_hour  = fromJSON(mvdash_votes_by_week_and_hour.raw)
#write.csv(mvdash_votes_by_week_and_hour , file = "mvdash_votes_by_week_and_hour.csv", row.names = FALSE)
dash = read.csv("dash-proposals.csv", stringsAsFactors = FALSE)
mean(dash$voter_participation)
mean(!is.na(dash$voter_participation)
)
head(dash)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals.raw = getURL("https://api.dashintel.org/dash_central_proposals")
dash_central_proposals = fromJSON(dash_central_proposals.raw)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dashprops = subset(dash_central_proposals, select = c("url", "title", "yes", "no", "abstain", "id", "date_added", "date_end", "budget_periods_timestamp", "startbudgetperiodtime"))
dashprops$eligible_voters = 0
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
dashprops$total_votes = dashprops$yes + dashprops$no + dashprops$abstain
dashprops$voter_participation = (dashprops$total_votes/dashprops$eligible_voters)*100
dashprops.finite = dashprops[is.finite(dashprops$voter_participation),]
dash = dashprops.finite
names(dash)[names(dash)=="yes"] <- "yes_votes"
names(dash)[names(dash)=="no"] <- "no_votes"
names(dash)[names(dash)=="date_added"] <- "voting_startdate"
names(dash)[names(dash)=="date_end"] <- "voting_enddate"
dash$project = "Dash"
dash = subset(dash, select = c("title","url","yes_votes","no_votes","total_votes","voter_participation","voting_startdate","voting_enddate","project","eligible_voters"))
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
mean(!is.na(dash$voter_participation))
head(dash)
nrow(dash)
mean(dash$voter_participation)
median(dash$voter_participation)
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
dash_central_proposals$startbudgetperiodtime = substr(dash_central_proposals$budget_periods_timestamp, 2, 11)
dash_central_proposals = dash_central_proposals[as.numeric(dash_central_proposals$startbudgetperiodtime) <= Sys.time(),]
dashprops = subset(dash_central_proposals, select = c("url", "title", "yes", "no", "abstain", "id", "date_added", "date_end", "budget_periods_timestamp", "startbudgetperiodtime"))
dashprops$eligible_voters = 0
for(p in dashprops$id)
{
print(p)
if(length(mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p] > 0)){
dashprops$budget_period_new[dashprops$id == p] = mvdash_proposals_unified$budget_period[mvdash_proposals_unified$id == p]
propdate = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$propdate[dashprops$id == p] = substr(dashprops$date_added[dashprops$id == p], 1, 10)
dashprops$eligible_voters[dashprops$id == p] = dash_mn_count$mn_count[dash_mn_count$date == propdate]
}
}
dashprops$total_votes = dashprops$yes + dashprops$no + dashprops$abstain
dashprops$voter_participation = (dashprops$total_votes/dashprops$eligible_voters)*100
dashprops.finite = dashprops[is.finite(dashprops$voter_participation),]
dash = dashprops.finite
names(dash)[names(dash)=="yes"] <- "yes_votes"
names(dash)[names(dash)=="no"] <- "no_votes"
names(dash)[names(dash)=="date_added"] <- "voting_startdate"
names(dash)[names(dash)=="date_end"] <- "voting_enddate"
dash$project = "Dash"
dash = subset(dash, select = c("title","url","yes_votes","no_votes","total_votes","voter_participation","voting_startdate","voting_enddate","project","eligible_voters"))
write.csv(dash, "dash-proposals.csv", row.names = FALSE)
nrow(dash)
mean(dash$voter_participation)
median(dash$voter_participation)
View(dash)
plot.proposal("950e8149e594b01c010c1199233ab11e82c9da39174ba375d286dc72bb0a54d7", "EXMO")
setwd("C:\\Users\\richa\\Documents\\GitHub\\pi-research\\data-collection")
source("functions-pi-analysis.R")
plot.proposal("950e8149e594b01c010c1199233ab11e82c9da39174ba375d286dc72bb0a54d7", "EXMO")
library(jsonlite)
library(RCurl)
library(plyr)
setwd("C:\\Users\\richa\\Documents\\GitHub\\mainnet")
#populate full list of proposals and version numbers
prop.id = fetch.proposals()
version = seq(1:length(prop.id))
proposals = data.frame(prop.id, version)
proposals$version = 0
proposals$prop.id = as.character(proposals$prop.id)
proposals$version = apply(proposals, 1, function(y) latest.version(y['prop.id']))
prop.comments = apply(proposals, 1, function(y) get.comments(y['prop.id'], y['version']))
df <- do.call("rbind", prop.comments)
df$comment.uid = paste(df$token, "/comments/", df$commentid, sep="")
df.comments = df[df$action == "add",]
df.comment.votes = df[df$action == "addlike",]
df.comments$score = 0
df.comments$votes = 0
df.comments$upvotes = 0
df.comments$downvotes = 0
df.comments$selfvotes = 0
for(p in unique(df.comments$token))
{
votes = df.comment.votes[df.comment.votes$token == p,]
comments = unique(votes$commentid)
for(c in comments)
{
commentowner = df.comments$publickey[df.comments$token == p & df.comments$commentid == c]
relvotes = votes[votes$commentid == c,]
score = sum(as.numeric(relvotes$vote))
commentvotes = length(as.numeric(relvotes$vote))
commentupvotes = length(as.numeric(relvotes$vote[relvotes$vote == 1]))
commentdownvotes = length(as.numeric(relvotes$vote[relvotes$vote == -1]))
commentselfvotes = sum(as.numeric(relvotes$vote[relvotes$publickey == commentowner]))
df.comments$score[df.comments$token == p & df.comments$commentid == c] = score
df.comments$votes[df.comments$token == p & df.comments$commentid == c] = commentvotes
df.comments$upvotes[df.comments$token == p & df.comments$commentid == c] = commentupvotes
df.comments$downvotes[df.comments$token == p & df.comments$commentid == c] = commentdownvotes
df.comments$selfvotes[df.comments$token == p & df.comments$commentid == c] = commentselfvotes
}
}
df.comments$selfvotes[df.comments$selfvotes == 2] = 0
df.comments$selfvotes[df.comments$selfvotes > 2] = 1
write.csv(df.comments, file = paste("pi-comments.csv", sep=""), row.names = FALSE)
write.csv(df.comment.votes, file = paste("pi-comment-votes.csv", sep=""), row.names = FALSE)
df.comment.votes$vote = as.numeric(df.comment.votes$vote)
#set last comment date
apply(proposals, 1, function(y) lastcomment(y['prop.id'], y['version']))
#process metadata.txt files
apply(proposals, 1, function(y) process00(y['prop.id'], y['version']))
proposals$updated_at = as.POSIXct(proposals$updated_at_unix, origin="1970-01-01")
apply(proposals, 1, function(y) process02(y['prop.id'], y['version']))
proposals$published_at = as.POSIXct(proposals$published_at_unix, origin="1970-01-01")
#starts breaking down here
eligibletickets = apply(proposals, 1, function(y) process15(y['prop.id'], y['version']))
#humanreadable dates
for(p in proposals$prop.id)
{
tryCatch({
proposals$voting_starttime[proposals$prop.id == p] = get.time(proposals$voting_startblock[proposals$prop.id == p])
proposals$voting_endtime[proposals$prop.id == p] = get.time(proposals$voting_endblock[proposals$prop.id == p])
assign('proposals', proposals, envir=.GlobalEnv)
Sys.sleep(1)
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
proposals$voting_startdate = as.POSIXlt(proposals$voting_starttime, origin = "1970-01-01")
proposals$voting_enddate = as.POSIXlt(proposals$voting_endtime, origin = "1970-01-01")
#voting results
prop.votes = apply(proposals, 1, function(y) process.ballot(y['prop.id'], y['version']))
votes.df <- do.call("rbind", prop.votes)
fix.latevotes()
#update proposal comment and voting status
apply(proposals, 1, function(y) update.voting.status(y['prop.id']))
sapply(proposals$prop.id, last.activity)
sapply(proposals$prop.id, last.activity.notcomment)
voted.props = proposals[!is.na(proposals$voting_endtime),]
402/12
plot.proposal("950e8149e594b01c010c1199233ab11e82c9da39174ba375d286dc72bb0a54d7", "EXMO")
setwd("C:\\Users\\richa\\Documents\\GitHub\\crypo-price-analysis")
decred = read.csv("CMC-Decred-201719.csv", stringsAsFactors = FALSE)
Decred = read.csv("CMC-Decred-201719.csv", stringsAsFactors = FALSE)
Decred$project = "Decred"
BAT = read.csv("CMC-BAT-201719.csv", stringsAsFactors = FALSE)
BAT$project = "BAT"
Bitcoin = read.csv("CMC-Bitcoin-201719.csv", stringsAsFactors = FALSE)
Bitcoin$project = "Bitcoin"
Dash = read.csv("CMC-Dash-201719.csv", stringsAsFactors = FALSE)
Dash$project = "Dash"
Doge = read.csv("CMC-Doge-201719.csv", stringsAsFactors = FALSE)
Doge$project = "Doge"
Ethereum = read.csv("CMC-Ethereum-201719.csv", stringsAsFactors = FALSE)
Ethereum$project = "Ethereum"
Litecoin = read.csv("CMC-Litecoin-201719.csv", stringsAsFactors = FALSE)
Litecoin$project = "Litecoin"
Monero = read.csv("CMC-Monero-201719.csv", stringsAsFactors = FALSE)
Monero$project = "Monero"
Nano = read.csv("CMC-Nano-201719.csv", stringsAsFactors = FALSE)
Nano$project = "Nano"
Ripple = read.csv("CMC-Ripple-201719.csv", stringsAsFactors = FALSE)
Ripple$project = "Ripple"
zcash = read.csv("CMC-zcash-201719.csv", stringsAsFactors = FALSE)
zcash$project = "Zcash"
Decred = read.csv("CMC-Decred-201719.csv", stringsAsFactors = FALSE)
Decred$project = "Decred"
BAT = read.csv("CMC-BAT-201719.csv", stringsAsFactors = FALSE)
BAT$project = "BAT"
Bitcoin = read.csv("CMC-Bitcoin-201719.csv", stringsAsFactors = FALSE)
Bitcoin$project = "Bitcoin"
Dash = read.csv("CMC-Dash-201719.csv", stringsAsFactors = FALSE)
Dash$project = "Dash"
Doge = read.csv("CMC-Doge-201719.csv", stringsAsFactors = FALSE)
Doge$project = "Doge"
Ethereum = read.csv("CMC-Ethereum-201719.csv", stringsAsFactors = FALSE)
Ethereum$project = "Ethereum"
Litecoin = read.csv("CMC-Litecoin-201719.csv", stringsAsFactors = FALSE)
Litecoin$project = "Litecoin"
Monero = read.csv("CMC-Monero-201719.csv", stringsAsFactors = FALSE)
Monero$project = "Monero"
Nano = read.csv("CMC-Nano-201719.csv", stringsAsFactors = FALSE)
Nano$project = "Nano"
Ripple = read.csv("CMC-Ripple-201719.csv", stringsAsFactors = FALSE)
Ripple$project = "Ripple"
zcash = read.csv("CMC-zcash-201719.csv", stringsAsFactors = FALSE)
zcash$project = "Zcash"
Ripple = read.csv("CMC-Ripple-201719.csv", stringsAsFactors = FALSE)
Ripple$project = "Ripple"
df = rbind(BAT, Bitcoin, Dash, Decred, Doge, Ethereum, Litecoin, Monero, Nano, Ripple, zcash)
nrow(df)
View(df)
df$daychange = df$Open. - df$Close..
df$daychange_per = (df$daychange/df$Open.) * 100
?as.POSIXlt
head(df)
?format
#deal with Date
df$date = as.POSIXlt(df$Date, format = "%b %d, %Y")
ggplot(df, aes(x = date, y = daychange_per))+
geom_line()+
facet_wrap(~project, ncol = 1)
p.daily.volatility = ggplot(df, aes(x = date, y = daychange_per))+
geom_line()+
facet_wrap(~project, ncol = 1)
?xtabs
#crosstab of mean daychange_per by project
xtabs(daychange_per~project)
#crosstab of mean daychange_per by project
xtabs(daychange_per~project, df)
?xtabs
with(df, tapply(daychange_per, list(project = project), mean) )
with(df, tapply(daychange_per, list(project = project), sd) )
df1year = df[df$date > 1524664336,]
head(df1year)
with(df1year, tapply(daychange_per, list(project = project), sd) )
with(df1year, tapply(daychange_per, list(project = project), mean) )
with(df1year, tapply(daychange_per, list(project = project), sd) )
?write.table
write.csv(with(df, tapply(daychange_per, list(project = project), mean) ), file = "daychange.csv")
write.csv(with(df, tapply(daychange_per, list(project = project), sd) ), file = "daychange-sd-2yr.csv")
write.csvwith(df1year, tapply(daychange_per, list(project = project), sd) ), file = "daychange-sd-1yr.csv")
write.csv(with(df1year, tapply(daychange_per, list(project = project), sd) ), file = "daychange-sd-1yr.csv")
write.csv(with(df1year, tapply(daychange_per, list(project = project), mean) ), file = "daychange-mean-1yr.csv")
write.csv(with(df, tapply(daychange_per, list(project = project), mean) ), file = "daychange-mean-2yr.csv")
ggsave("daily-pricechange-2years.png", height = 12, width = 5)
